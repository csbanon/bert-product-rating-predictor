{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "colab": {
      "name": "Star_Prediction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "482f6ae248274c9782b0d5e61020a2f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_95a94d7b3ad1462fb0f16a27a3a6efbf",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_713aaa83768846f19308007d9b69827d",
              "IPY_MODEL_0396fd9b38e948a6895930cf01b6d67d"
            ]
          }
        },
        "95a94d7b3ad1462fb0f16a27a3a6efbf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "713aaa83768846f19308007d9b69827d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_71531f137b7e4b5ea356ccde625d4a99",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_332b75eb37114ac785acaaf5b392d1ce"
          }
        },
        "0396fd9b38e948a6895930cf01b6d67d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c2dfdac069dd4a6a9bcfdfd43fd9d939",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:02&lt;00:00, 183B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1a32bd6a32df4fefae34256e1cb03800"
          }
        },
        "71531f137b7e4b5ea356ccde625d4a99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "332b75eb37114ac785acaaf5b392d1ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c2dfdac069dd4a6a9bcfdfd43fd9d939": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1a32bd6a32df4fefae34256e1cb03800": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5a407a98839b49828a3d9fe1fcd018b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9cc23f1d06a740a3ac6c96b86fbad7e9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3947a276c4b347238aaf78605425c78f",
              "IPY_MODEL_b088ed92e61e4b99bd2216334a0c89fd"
            ]
          }
        },
        "9cc23f1d06a740a3ac6c96b86fbad7e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3947a276c4b347238aaf78605425c78f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_86467be836cc4feb9760f080995a9078",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4c90185586934b7e87b5ab6a0cb6910d"
          }
        },
        "b088ed92e61e4b99bd2216334a0c89fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_71e8e7793688403ab6564ad4712b0f32",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 305kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_497293d5c5eb4c51a535a4e40cafac74"
          }
        },
        "86467be836cc4feb9760f080995a9078": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4c90185586934b7e87b5ab6a0cb6910d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "71e8e7793688403ab6564ad4712b0f32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "497293d5c5eb4c51a535a4e40cafac74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f7734ca795f94f0380450bf4650b203f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a0b3d2602b0e4c0cb7c6bc0b0321147f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_41a89726bc0d470f87ecc7410211f2e2",
              "IPY_MODEL_a38ef014a104450b9ce6d738b0403461"
            ]
          }
        },
        "a0b3d2602b0e4c0cb7c6bc0b0321147f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "41a89726bc0d470f87ecc7410211f2e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_877887366a264350824242efadf725ea",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9e8574548fa04c8f9a89ba372e1442d2"
          }
        },
        "a38ef014a104450b9ce6d738b0403461": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b79df17803af4e0d9acdf4b1f07ba3fa",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:06&lt;00:00, 70.7MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c629e2cf819842b384f797b9d4cdb622"
          }
        },
        "877887366a264350824242efadf725ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9e8574548fa04c8f9a89ba372e1442d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b79df17803af4e0d9acdf4b1f07ba3fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c629e2cf819842b384f797b9d4cdb622": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "XodI4wEPZXMX",
        "outputId": "700886ec-870c-4387-9746-3b9ec5fcabe6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (3.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.94)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: tokenizers==0.9.2 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.9.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers) (3.12.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (50.3.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9w-FKL1SY3us"
      },
      "source": [
        "import glob\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import sys\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoTokenizer, BertModel, BertForSequenceClassification"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ec17VSn1waWr",
        "outputId": "77bffe5b-8fa3-416a-d00d-a85cbe37e390",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iymHBx_p762"
      },
      "source": [
        "## Get Preprocessed Review Data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xt6v07EKpKss",
        "outputId": "336ff5b8-e38c-477f-d91a-b54cee916d6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        }
      },
      "source": [
        "github_url = 'https://raw.githubusercontent.com/csbanon/bert-product-rating-predictor/master/data/reviews_comments_stars.csv'\n",
        "df = pd.read_csv(github_url)\n",
        "df = df[['comment', 'stars']]\n",
        "df"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment</th>\n",
              "      <th>stars</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I could sit here and write all about the specs...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A very reasonably priced laptop for basic comp...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>This is the best laptop deal you can get, full...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A few months after the purchase....It is still...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>BUYER BE AWARE: This computer has Microsoft 10...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195760</th>\n",
              "      <td>I have not tried this camera without the SD ca...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195761</th>\n",
              "      <td>Hello, I bought this item months ago and I tho...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195762</th>\n",
              "      <td>This is an incredible camera for the money!!  ...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195763</th>\n",
              "      <td>Great cameras. Purchased some for my mother af...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195764</th>\n",
              "      <td>Just getting it set up and seem s to work well...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>195765 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  comment  stars\n",
              "0       I could sit here and write all about the specs...      5\n",
              "1       A very reasonably priced laptop for basic comp...      4\n",
              "2       This is the best laptop deal you can get, full...      5\n",
              "3       A few months after the purchase....It is still...      5\n",
              "4       BUYER BE AWARE: This computer has Microsoft 10...      1\n",
              "...                                                   ...    ...\n",
              "195760  I have not tried this camera without the SD ca...      5\n",
              "195761  Hello, I bought this item months ago and I tho...      1\n",
              "195762  This is an incredible camera for the money!!  ...      5\n",
              "195763  Great cameras. Purchased some for my mother af...      5\n",
              "195764  Just getting it set up and seem s to work well...      5\n",
              "\n",
              "[195765 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7h58sp8jGA1e"
      },
      "source": [
        "## Define the neural model for fine tuning\n",
        "Given a review as an input sequence, we want to predict its star rating. This is a multi-class sequence classification task.\n",
        "\n",
        "For out model, we will use BertForSequenceClassification and set the num_labels argument to the number of unique values for Amazon star ratings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HE9UIbL4KY74",
        "outputId": "d0682dd9-1b6b-45d9-d339-337ac48dc123",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cuda'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zy77n9g_FxX8",
        "outputId": "438abeca-f83b-41e8-c92c-abc4c3cef5bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "482f6ae248274c9782b0d5e61020a2f8",
            "95a94d7b3ad1462fb0f16a27a3a6efbf",
            "713aaa83768846f19308007d9b69827d",
            "0396fd9b38e948a6895930cf01b6d67d",
            "71531f137b7e4b5ea356ccde625d4a99",
            "332b75eb37114ac785acaaf5b392d1ce",
            "c2dfdac069dd4a6a9bcfdfd43fd9d939",
            "1a32bd6a32df4fefae34256e1cb03800",
            "5a407a98839b49828a3d9fe1fcd018b3",
            "9cc23f1d06a740a3ac6c96b86fbad7e9",
            "3947a276c4b347238aaf78605425c78f",
            "b088ed92e61e4b99bd2216334a0c89fd",
            "86467be836cc4feb9760f080995a9078",
            "4c90185586934b7e87b5ab6a0cb6910d",
            "71e8e7793688403ab6564ad4712b0f32",
            "497293d5c5eb4c51a535a4e40cafac74",
            "f7734ca795f94f0380450bf4650b203f",
            "a0b3d2602b0e4c0cb7c6bc0b0321147f",
            "41a89726bc0d470f87ecc7410211f2e2",
            "a38ef014a104450b9ce6d738b0403461",
            "877887366a264350824242efadf725ea",
            "9e8574548fa04c8f9a89ba372e1442d2",
            "b79df17803af4e0d9acdf4b1f07ba3fa",
            "c629e2cf819842b384f797b9d4cdb622"
          ]
        }
      },
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\",\n",
        "    num_labels = len(df['stars'].unique()), # number of unique labels for our multi-class classification problem\n",
        "    output_attentions = False,\n",
        "    output_hidden_states = False,\n",
        ")\n",
        "model.to(device)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "482f6ae248274c9782b0d5e61020a2f8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5a407a98839b49828a3d9fe1fcd018b3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f7734ca795f94f0380450bf4650b203f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descriâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kt_mx_Z3GGCD"
      },
      "source": [
        "## Define the Reviews Dataset\n",
        "Each item in the dataset will return a dictionary consisting of:\n",
        "\n",
        "\n",
        "*   input_ids: the input token ids\n",
        "*   attn_mask: the attention mask of the input sequence\n",
        "*   label: the target star rating of the input review"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbIXeGa0Y3vH"
      },
      "source": [
        "class ReviewsDataset(Dataset):\n",
        "    def __init__(self, df, max_length=512):\n",
        "        self.df = df\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
        "        self.max_length = max_length \n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        # input=review, label=stars\n",
        "        review = self.df.loc[idx, 'comment']\n",
        "        # labels are 0-indexed\n",
        "        label = int(self.df.loc[idx, 'stars']) - 1\n",
        "        \n",
        "        encoded = self.tokenizer(\n",
        "            review,                      # review to encode\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_length,  # Truncate all segments to max_length\n",
        "            padding='max_length',        # pad all reviews with the [PAD] token to the max_length\n",
        "            return_attention_mask=True,  # Construct attention masks.\n",
        "            truncation=True\n",
        "        )\n",
        "        \n",
        "        input_ids = encoded['input_ids']\n",
        "        attn_mask = encoded['attention_mask']\n",
        "        \n",
        "        return {\n",
        "            'input_ids': torch.tensor(input_ids),\n",
        "            'attn_mask': torch.tensor(attn_mask), \n",
        "            'label': torch.tensor(label)\n",
        "        }"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDymyf0zvFt0"
      },
      "source": [
        "Define some constants that are important later on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6R4CqyQMY3vI"
      },
      "source": [
        "MAX_LEN = 256\n",
        "TEST_SIZE = 0.2\n",
        "VAL_SIZE = 0.125\n",
        "TRAIN_BATCH_SIZE = 32\n",
        "TEST_BATCH_SIZE = 16\n",
        "\n",
        "CHECKPOINT_FILE = 'checkpoint.dat'\n",
        "CHECKPOINT_FOLDER = 'Checkpoint'\n",
        "EPOCHS = 4\n",
        "LEARNING_RATE = 5e-05\n",
        "PROJECT_FOLDER = '/content/drive/My Drive/BERT project/'\n",
        "MODEL_FOLDER = 'Model'\n",
        "SAVE_EVERY = 100\n",
        "NUM_WORKERS = 4"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0p0Abyju3iT"
      },
      "source": [
        "## Create Datasets / DataLoaders\n",
        "Create the train and test datasets and dataloaders for the neural network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fP9HLK63sdji",
        "outputId": "d39799dd-680e-4135-a94f-18aa7c9ecbf2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_dataset, test_dataset = train_test_split(df, test_size=TEST_SIZE, random_state=1)\n",
        "train_dataset, val_dataset = train_test_split(train_dataset, test_size=VAL_SIZE, random_state=1)\n",
        "\n",
        "train_dataset = train_dataset.reset_index(drop=True)\n",
        "val_dataset = val_dataset.reset_index(drop=True)\n",
        "test_dataset = test_dataset.reset_index(drop=True)\n",
        "\n",
        "train_set = ReviewsDataset(train_dataset, MAX_LEN)\n",
        "val_set = ReviewsDataset(val_dataset, MAX_LEN)\n",
        "test_set = ReviewsDataset(test_dataset, MAX_LEN)\n",
        "\n",
        "print(\"# of samples in train set: {}\".format(len(train_set)))\n",
        "print(\"# of samples in val set: {}\".format(len(val_set)))\n",
        "print(\"# of samples in test set: {}\".format(len(test_set)))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# of samples in train set: 137035\n",
            "# of samples in val set: 19577\n",
            "# of samples in test set: 39153\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9L9c9iFDY3vM"
      },
      "source": [
        "train_params = {\n",
        "                'batch_size': TRAIN_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': NUM_WORKERS\n",
        "                }\n",
        "val_params = train_params\n",
        "\n",
        "test_params = {\n",
        "                'batch_size': TEST_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': NUM_WORKERS\n",
        "              }\n",
        "\n",
        "train_loader = DataLoader(train_set, **train_params)\n",
        "val_loader = DataLoader(val_set, **val_params)\n",
        "test_loader = DataLoader(test_set, **test_params)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3mQyVauw6At"
      },
      "source": [
        "## Define the neural model for fine tuning\n",
        "Given a review as an input sequence, we want to predict its star rating. This is a multi-class sequence classification task.\n",
        "\n",
        "For out model, we will use BertForSequenceClassification and set the num_labels argument to the number of unique values for Amazon star ratings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfNsRkv2z-11"
      },
      "source": [
        "## Fine Tuning the Model on Train Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QySwvdEfuyQw"
      },
      "source": [
        "# Define the optimizer\n",
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TWcRWb5txai"
      },
      "source": [
        "# Define the accuracy function\n",
        "def calculate_accuracy(big_idx, targets):\n",
        "    n_correct = (big_idx==targets).sum().item()\n",
        "    return n_correct"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpQBeI3jMSyz"
      },
      "source": [
        "# For validation and testing\n",
        "def validate(model, data_loader):\n",
        "    model.eval()\n",
        "    n_correct = 0 \n",
        "    nb_test_steps = 0\n",
        "    nb_test_examples = 0\n",
        "    test_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for _, data in enumerate(data_loader, 0):\n",
        "            input_ids = data['input_ids'].to(device)\n",
        "            mask = data['attn_mask'].to(device)\n",
        "            labels = data['label'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, mask)\n",
        "            loss = loss_function(outputs[0], labels)\n",
        "            test_loss += loss.item()\n",
        "\n",
        "            # gets labels with highest probabilities and their corresponding indices\n",
        "            big_val, big_idx = torch.max(outputs[0].data, dim=1)\n",
        "            n_correct += calculate_accuracy(big_idx, labels)\n",
        "\n",
        "            nb_test_steps += 1\n",
        "            nb_test_examples += labels.size(0)\n",
        "            \n",
        "    epoch_loss = test_loss/nb_test_steps\n",
        "    epoch_accu = (n_correct*100)/nb_test_examples\n",
        "    print(f\"Validation Loss: {epoch_loss}\")\n",
        "    print(f\"Validation Accuracy: {epoch_accu}\\n\")\n",
        "    \n",
        "    return epoch_accu"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMpY_1OgzG3K"
      },
      "source": [
        "# Training loop\n",
        "def train(epoch):\n",
        "    # number of batches run by model\n",
        "    nb_tr_steps = 0\n",
        "    # number of training examples run by model\n",
        "    nb_tr_examples = 0\n",
        "    # number of examples classified correctly by model\n",
        "    n_correct = 0\n",
        "    tr_loss = 0\n",
        "    model.train()\n",
        "\n",
        "    for batch, data in enumerate(train_loader):\n",
        "        input_ids = data['input_ids'].to(device)\n",
        "        mask = data['attn_mask'].to(device)\n",
        "        labels = data['label'].to(device)\n",
        "\n",
        "        outputs = model(input_ids, mask)\n",
        "        loss = loss_function(outputs[0], labels)\n",
        "        tr_loss += loss.item()\n",
        "\n",
        "        # gets labels with highest probabilities and their corresponding indices\n",
        "        big_val, big_idx = torch.max(outputs[0].data, dim=1)\n",
        "        n_correct += calculate_accuracy(big_idx, labels)\n",
        "\n",
        "        nb_tr_steps += 1\n",
        "        nb_tr_examples+=labels.size(0)\n",
        "        \n",
        "        if batch % SAVE_EVERY == 0:\n",
        "            loss_step = tr_loss/nb_tr_steps\n",
        "            accu_step = (n_correct*100)/nb_tr_examples \n",
        "            print(\"Batch {} of epoch {} complete.\".format(batch, epoch+1))\n",
        "            print(f\"Training Loss: {loss_step}   Training Accuracy: {accu_step}\")\n",
        "\n",
        "            if not os.path.exists(CHECKPOINT_FOLDER):\n",
        "              os.makedirs(CHECKPOINT_FOLDER)\n",
        "\n",
        "            # Since a single epoch could take well over hours, we regularly save the model even during evaluation of training accuracy.\n",
        "            torch.save(model.state_dict(), os.path.join(PROJECT_FOLDER, CHECKPOINT_FOLDER, CHECKPOINT_FILE))\n",
        "            print(\"Saving checkpoint at\", os.path.join(PROJECT_FOLDER, CHECKPOINT_FOLDER, CHECKPOINT_FILE))\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        # When using GPU\n",
        "        optimizer.step()\n",
        "\n",
        "    print('\\n*****\\n')\n",
        "    print(f'The Total Accuracy for Epoch {epoch+1}: {(n_correct*100)/nb_tr_examples}')\n",
        "    epoch_loss = tr_loss/nb_tr_steps\n",
        "    epoch_accu = (n_correct*100)/nb_tr_examples\n",
        "    print(f\"Training Loss: {epoch_loss}\")\n",
        "    print(f\"Training Accuracy: {epoch_accu}\\n\")\n",
        "\n",
        "    # Evaluate model after training it on this epoch\n",
        "    validate(model, val_loader)\n",
        "\n",
        "    torch.save(model.state_dict(), os.path.join(PROJECT_FOLDER, CHECKPOINT_FOLDER, CHECKPOINT_FILE))\n",
        "    model.save_pretrained(os.path.join(PROJECT_FOLDER, MODEL_FOLDER, str(epoch+1)))\n",
        "    print(\"Saving checkpoint at \", os.path.join(PROJECT_FOLDER, CHECKPOINT_FOLDER, CHECKPOINT_FILE))\n",
        "    print(\"Saving model at \", os.path.join(PROJECT_FOLDER, MODEL_FOLDER, str(epoch+1)), '\\n\\n================================================\\n')\n",
        "\n",
        "    return"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0Z_p-zKDYL8",
        "outputId": "64901ec4-32cb-4ce3-b7de-f46650b9aa1d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for epoch in range(EPOCHS):\n",
        "    train(epoch)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Batch 0 of epoch 1 complete.\n",
            "Training Loss: 1.4860026836395264   Training Accuracy: 43.75\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 100 of epoch 1 complete.\n",
            "Training Loss: 0.8057475671319678   Training Accuracy: 73.26732673267327\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 200 of epoch 1 complete.\n",
            "Training Loss: 0.7524730669918345   Training Accuracy: 74.09825870646766\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 300 of epoch 1 complete.\n",
            "Training Loss: 0.7184093109397001   Training Accuracy: 74.78197674418605\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 400 of epoch 1 complete.\n",
            "Training Loss: 0.7000823977433536   Training Accuracy: 75.31172069825436\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 500 of epoch 1 complete.\n",
            "Training Loss: 0.6807707369684459   Training Accuracy: 75.76097804391217\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 600 of epoch 1 complete.\n",
            "Training Loss: 0.6745561910250818   Training Accuracy: 75.92034109816971\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 700 of epoch 1 complete.\n",
            "Training Loss: 0.6654289693873211   Training Accuracy: 76.11002139800286\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 800 of epoch 1 complete.\n",
            "Training Loss: 0.6605690370003382   Training Accuracy: 76.24843945068665\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 900 of epoch 1 complete.\n",
            "Training Loss: 0.6557541266001025   Training Accuracy: 76.37347391786903\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 1000 of epoch 1 complete.\n",
            "Training Loss: 0.6538757256396881   Training Accuracy: 76.36426073926074\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 1100 of epoch 1 complete.\n",
            "Training Loss: 0.648839499087468   Training Accuracy: 76.49012261580381\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 1200 of epoch 1 complete.\n",
            "Training Loss: 0.6464139953143988   Training Accuracy: 76.5429850124896\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 1300 of epoch 1 complete.\n",
            "Training Loss: 0.6398211663544499   Training Accuracy: 76.78948885472714\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 1400 of epoch 1 complete.\n",
            "Training Loss: 0.6350813409862648   Training Accuracy: 76.8981977159172\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 1500 of epoch 1 complete.\n",
            "Training Loss: 0.6312146468967854   Training Accuracy: 77.02156895403064\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 1600 of epoch 1 complete.\n",
            "Training Loss: 0.6292679098380647   Training Accuracy: 77.04950031230481\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 1700 of epoch 1 complete.\n",
            "Training Loss: 0.6273463311649504   Training Accuracy: 77.06863609641387\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 1800 of epoch 1 complete.\n",
            "Training Loss: 0.6244783950705849   Training Accuracy: 77.18802054414215\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 1900 of epoch 1 complete.\n",
            "Training Loss: 0.6230564639168247   Training Accuracy: 77.26196738558653\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 2000 of epoch 1 complete.\n",
            "Training Loss: 0.6207905551125442   Training Accuracy: 77.3597576211894\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 2100 of epoch 1 complete.\n",
            "Training Loss: 0.618708712934937   Training Accuracy: 77.4184911946692\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 2200 of epoch 1 complete.\n",
            "Training Loss: 0.6164843662930098   Training Accuracy: 77.51874148114493\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 2300 of epoch 1 complete.\n",
            "Training Loss: 0.6148570578080682   Training Accuracy: 77.58175793133421\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 2400 of epoch 1 complete.\n",
            "Training Loss: 0.6125049491020006   Training Accuracy: 77.65644523115368\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 2500 of epoch 1 complete.\n",
            "Training Loss: 0.6119175264712383   Training Accuracy: 77.65893642542983\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 2600 of epoch 1 complete.\n",
            "Training Loss: 0.6110261038020225   Training Accuracy: 77.69127258746636\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 2700 of epoch 1 complete.\n",
            "Training Loss: 0.6107425394377325   Training Accuracy: 77.65873750462792\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 2800 of epoch 1 complete.\n",
            "Training Loss: 0.609378037448229   Training Accuracy: 77.68765619421634\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 2900 of epoch 1 complete.\n",
            "Training Loss: 0.6078198901469113   Training Accuracy: 77.74797483626335\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 3000 of epoch 1 complete.\n",
            "Training Loss: 0.606567731850229   Training Accuracy: 77.77303398867045\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 3100 of epoch 1 complete.\n",
            "Training Loss: 0.6053281408602175   Training Accuracy: 77.81260077394388\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 3200 of epoch 1 complete.\n",
            "Training Loss: 0.6046221877673164   Training Accuracy: 77.84481412058732\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 3300 of epoch 1 complete.\n",
            "Training Loss: 0.6027637597188124   Training Accuracy: 77.89022265980006\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 3400 of epoch 1 complete.\n",
            "Training Loss: 0.602412615412826   Training Accuracy: 77.89345045574831\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 3500 of epoch 1 complete.\n",
            "Training Loss: 0.6024172794125959   Training Accuracy: 77.86257497857756\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 3600 of epoch 1 complete.\n",
            "Training Loss: 0.6012717673751057   Training Accuracy: 77.91846014995835\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 3700 of epoch 1 complete.\n",
            "Training Loss: 0.600253819614061   Training Accuracy: 77.94430559308294\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 3800 of epoch 1 complete.\n",
            "Training Loss: 0.5987895334732906   Training Accuracy: 77.99592212575638\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 3900 of epoch 1 complete.\n",
            "Training Loss: 0.5982292144573886   Training Accuracy: 78.02566649577031\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 4000 of epoch 1 complete.\n",
            "Training Loss: 0.5972055393445495   Training Accuracy: 78.06251562109473\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 4100 of epoch 1 complete.\n",
            "Training Loss: 0.5968650055604573   Training Accuracy: 78.06327724945136\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 4200 of epoch 1 complete.\n",
            "Training Loss: 0.596140697087682   Training Accuracy: 78.07292906450844\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "\n",
            "*****\n",
            "\n",
            "The Total Accuracy for Epoch 1: 78.10340423979275\n",
            "Training Loss: 0.5953439118746366\n",
            "Training Accuracy: 78.10340423979275\n",
            "\n",
            "Validation Loss: 0.5751560729946575\n",
            "Validation Accuracy: 78.58200950094499\n",
            "\n",
            "Saving checkpoint at  /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Saving model at  /content/drive/My Drive/BERT project/Model/1 \n",
            "\n",
            "================================================\n",
            "\n",
            "Batch 0 of epoch 2 complete.\n",
            "Training Loss: 0.5535005331039429   Training Accuracy: 75.0\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 100 of epoch 2 complete.\n",
            "Training Loss: 0.4839566704070214   Training Accuracy: 82.08539603960396\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 200 of epoch 2 complete.\n",
            "Training Loss: 0.49366001547569066   Training Accuracy: 81.66977611940298\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 300 of epoch 2 complete.\n",
            "Training Loss: 0.49592850240956116   Training Accuracy: 81.55107973421927\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 400 of epoch 2 complete.\n",
            "Training Loss: 0.49943892133800766   Training Accuracy: 81.56951371571073\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 500 of epoch 2 complete.\n",
            "Training Loss: 0.5038720531734878   Training Accuracy: 81.3186127744511\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 600 of epoch 2 complete.\n",
            "Training Loss: 0.5113618236016513   Training Accuracy: 80.98481697171381\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 700 of epoch 2 complete.\n",
            "Training Loss: 0.5075598972585164   Training Accuracy: 80.98252496433666\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 800 of epoch 2 complete.\n",
            "Training Loss: 0.509014817473296   Training Accuracy: 80.7857365792759\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 900 of epoch 2 complete.\n",
            "Training Loss: 0.508541555684494   Training Accuracy: 80.77830188679245\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 1000 of epoch 2 complete.\n",
            "Training Loss: 0.5093772002867052   Training Accuracy: 80.79732767232767\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 1100 of epoch 2 complete.\n",
            "Training Loss: 0.5106798579999255   Training Accuracy: 80.84411898274296\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 1200 of epoch 2 complete.\n",
            "Training Loss: 0.510975712480692   Training Accuracy: 80.7946502914238\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 1300 of epoch 2 complete.\n",
            "Training Loss: 0.5118820203853331   Training Accuracy: 80.81283627978478\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 1400 of epoch 2 complete.\n",
            "Training Loss: 0.5122126389366657   Training Accuracy: 80.74589578872234\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 1500 of epoch 2 complete.\n",
            "Training Loss: 0.51054579025503   Training Accuracy: 80.8065456362425\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 1600 of epoch 2 complete.\n",
            "Training Loss: 0.5092506484081416   Training Accuracy: 80.82253279200499\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 1700 of epoch 2 complete.\n",
            "Training Loss: 0.5085725123079156   Training Accuracy: 80.84398883009995\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 1800 of epoch 2 complete.\n",
            "Training Loss: 0.5079345495286482   Training Accuracy: 80.87347307051638\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 1900 of epoch 2 complete.\n",
            "Training Loss: 0.5082093356221303   Training Accuracy: 80.86862177801157\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 2000 of epoch 2 complete.\n",
            "Training Loss: 0.5076025856443789   Training Accuracy: 80.88924287856072\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 2100 of epoch 2 complete.\n",
            "Training Loss: 0.5080399934888624   Training Accuracy: 80.8469181342218\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 2200 of epoch 2 complete.\n",
            "Training Loss: 0.5081191079784989   Training Accuracy: 80.86097228532485\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 2300 of epoch 2 complete.\n",
            "Training Loss: 0.5083206257564717   Training Accuracy: 80.86294002607562\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 2400 of epoch 2 complete.\n",
            "Training Loss: 0.5079780885362466   Training Accuracy: 80.89467930029154\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 2500 of epoch 2 complete.\n",
            "Training Loss: 0.5075582747683912   Training Accuracy: 80.92263094762095\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 2600 of epoch 2 complete.\n",
            "Training Loss: 0.5078187804527349   Training Accuracy: 80.90277777777777\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 2700 of epoch 2 complete.\n",
            "Training Loss: 0.5081461659297816   Training Accuracy: 80.87745279526102\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 2800 of epoch 2 complete.\n",
            "Training Loss: 0.5075106526997973   Training Accuracy: 80.8996786861835\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 2900 of epoch 2 complete.\n",
            "Training Loss: 0.5070006745549286   Training Accuracy: 80.92899000344708\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 3000 of epoch 2 complete.\n",
            "Training Loss: 0.5062784882549721   Training Accuracy: 80.95322392535822\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 3100 of epoch 2 complete.\n",
            "Training Loss: 0.5061219727890178   Training Accuracy: 80.96783295711062\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 3200 of epoch 2 complete.\n",
            "Training Loss: 0.5066261457902533   Training Accuracy: 80.93076382380507\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 3300 of epoch 2 complete.\n",
            "Training Loss: 0.5070240063216426   Training Accuracy: 80.90635413511058\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 3400 of epoch 2 complete.\n",
            "Training Loss: 0.5070165385944252   Training Accuracy: 80.91645839458982\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 3500 of epoch 2 complete.\n",
            "Training Loss: 0.5072157737873207   Training Accuracy: 80.90813339045987\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 3600 of epoch 2 complete.\n",
            "Training Loss: 0.507197684505207   Training Accuracy: 80.89940294362677\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 3700 of epoch 2 complete.\n",
            "Training Loss: 0.5070293652116689   Training Accuracy: 80.9114090786274\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 3800 of epoch 2 complete.\n",
            "Training Loss: 0.5077156243226899   Training Accuracy: 80.89154169955275\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 3900 of epoch 2 complete.\n",
            "Training Loss: 0.5085641272734661   Training Accuracy: 80.85907459625737\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 4000 of epoch 2 complete.\n",
            "Training Loss: 0.508828382137432   Training Accuracy: 80.83682204448888\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 4100 of epoch 2 complete.\n",
            "Training Loss: 0.5086419791677207   Training Accuracy: 80.84080102414045\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 4200 of epoch 2 complete.\n",
            "Training Loss: 0.5086201724215679   Training Accuracy: 80.846822185194\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "\n",
            "*****\n",
            "\n",
            "The Total Accuracy for Epoch 2: 80.85160725362134\n",
            "Training Loss: 0.5084229788381781\n",
            "Training Accuracy: 80.85160725362134\n",
            "\n",
            "Validation Loss: 0.57492244499279\n",
            "Validation Accuracy: 79.28691832252133\n",
            "\n",
            "Saving checkpoint at  /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Saving model at  /content/drive/My Drive/BERT project/Model/2 \n",
            "\n",
            "================================================\n",
            "\n",
            "Batch 0 of epoch 3 complete.\n",
            "Training Loss: 0.44540295004844666   Training Accuracy: 84.375\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 100 of epoch 3 complete.\n",
            "Training Loss: 0.4330317435583266   Training Accuracy: 83.63242574257426\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 200 of epoch 3 complete.\n",
            "Training Loss: 0.42747591584179534   Training Accuracy: 83.92412935323384\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 300 of epoch 3 complete.\n",
            "Training Loss: 0.44170830846822934   Training Accuracy: 83.32641196013289\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 400 of epoch 3 complete.\n",
            "Training Loss: 0.43664450859859993   Training Accuracy: 83.47100997506234\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 500 of epoch 3 complete.\n",
            "Training Loss: 0.43483473281719964   Training Accuracy: 83.53917165668663\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 600 of epoch 3 complete.\n",
            "Training Loss: 0.43480607449462927   Training Accuracy: 83.58465058236273\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 700 of epoch 3 complete.\n",
            "Training Loss: 0.4324134108364667   Training Accuracy: 83.69739657631955\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 800 of epoch 3 complete.\n",
            "Training Loss: 0.4349828921584005   Training Accuracy: 83.61033083645444\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 900 of epoch 3 complete.\n",
            "Training Loss: 0.43418272660753704   Training Accuracy: 83.57727524972253\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 1000 of epoch 3 complete.\n",
            "Training Loss: 0.43519240703348155   Training Accuracy: 83.4758991008991\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 1100 of epoch 3 complete.\n",
            "Training Loss: 0.43507745579142226   Training Accuracy: 83.46957311534968\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 1200 of epoch 3 complete.\n",
            "Training Loss: 0.4335540781956132   Training Accuracy: 83.57098251457118\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 1300 of epoch 3 complete.\n",
            "Training Loss: 0.43353149795376456   Training Accuracy: 83.61356648731744\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 1400 of epoch 3 complete.\n",
            "Training Loss: 0.43366106753260814   Training Accuracy: 83.59653818700927\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 1500 of epoch 3 complete.\n",
            "Training Loss: 0.43387326233828566   Training Accuracy: 83.62133577614924\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 1600 of epoch 3 complete.\n",
            "Training Loss: 0.435606938313872   Training Accuracy: 83.57081511555278\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 1700 of epoch 3 complete.\n",
            "Training Loss: 0.434829103655846   Training Accuracy: 83.62176660787772\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 1800 of epoch 3 complete.\n",
            "Training Loss: 0.4347590135161179   Training Accuracy: 83.61500555247085\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 1900 of epoch 3 complete.\n",
            "Training Loss: 0.4354337303341219   Training Accuracy: 83.59087322461862\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 2000 of epoch 3 complete.\n",
            "Training Loss: 0.4349323886594196   Training Accuracy: 83.61288105947027\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 2100 of epoch 3 complete.\n",
            "Training Loss: 0.4358679152269808   Training Accuracy: 83.59709662065683\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 2200 of epoch 3 complete.\n",
            "Training Loss: 0.4367450832074905   Training Accuracy: 83.54441163107678\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 2300 of epoch 3 complete.\n",
            "Training Loss: 0.43724826851237186   Training Accuracy: 83.52075184702304\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 2400 of epoch 3 complete.\n",
            "Training Loss: 0.43747153200801836   Training Accuracy: 83.49645980841316\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 2500 of epoch 3 complete.\n",
            "Training Loss: 0.43702004282999307   Training Accuracy: 83.51659336265494\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 2600 of epoch 3 complete.\n",
            "Training Loss: 0.43725964936303524   Training Accuracy: 83.52316416762784\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 2700 of epoch 3 complete.\n",
            "Training Loss: 0.4372328034526593   Training Accuracy: 83.52114957423177\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 2800 of epoch 3 complete.\n",
            "Training Loss: 0.43807059670879944   Training Accuracy: 83.51481613709389\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 2900 of epoch 3 complete.\n",
            "Training Loss: 0.43842794044506384   Training Accuracy: 83.50676490865219\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 3000 of epoch 3 complete.\n",
            "Training Loss: 0.43844132740342273   Training Accuracy: 83.49196101299567\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 3100 of epoch 3 complete.\n",
            "Training Loss: 0.43894562127848896   Training Accuracy: 83.49725894872621\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 3200 of epoch 3 complete.\n",
            "Training Loss: 0.43960377493199987   Training Accuracy: 83.4885582630428\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 3300 of epoch 3 complete.\n",
            "Training Loss: 0.43974637545778406   Training Accuracy: 83.47754468342926\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 3400 of epoch 3 complete.\n",
            "Training Loss: 0.44047225684242997   Training Accuracy: 83.44880182299323\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 3500 of epoch 3 complete.\n",
            "Training Loss: 0.44004569430796975   Training Accuracy: 83.47972007997716\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 3600 of epoch 3 complete.\n",
            "Training Loss: 0.4403140035516618   Training Accuracy: 83.46466259372397\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 3700 of epoch 3 complete.\n",
            "Training Loss: 0.44060124940234113   Training Accuracy: 83.44281950824102\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 3800 of epoch 3 complete.\n",
            "Training Loss: 0.440246413149463   Training Accuracy: 83.44021310181532\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 3900 of epoch 3 complete.\n",
            "Training Loss: 0.44057921864907884   Training Accuracy: 83.42412201999487\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 4000 of epoch 3 complete.\n",
            "Training Loss: 0.4410702920938039   Training Accuracy: 83.38462259435141\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 4100 of epoch 3 complete.\n",
            "Training Loss: 0.4416812350530649   Training Accuracy: 83.3630516947086\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 4200 of epoch 3 complete.\n",
            "Training Loss: 0.442129968669309   Training Accuracy: 83.34622708878838\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "\n",
            "*****\n",
            "\n",
            "The Total Accuracy for Epoch 3: 83.34732002773015\n",
            "Training Loss: 0.4423234376194403\n",
            "Training Accuracy: 83.34732002773015\n",
            "\n",
            "Validation Loss: 0.5907580286045285\n",
            "Validation Accuracy: 78.86295142258773\n",
            "\n",
            "Saving checkpoint at  /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Saving model at  /content/drive/My Drive/BERT project/Model/3 \n",
            "\n",
            "================================================\n",
            "\n",
            "Batch 0 of epoch 4 complete.\n",
            "Training Loss: 0.3792751729488373   Training Accuracy: 87.5\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 100 of epoch 4 complete.\n",
            "Training Loss: 0.3318087412136616   Training Accuracy: 87.59282178217822\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 200 of epoch 4 complete.\n",
            "Training Loss: 0.3310927655269851   Training Accuracy: 87.62437810945273\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 300 of epoch 4 complete.\n",
            "Training Loss: 0.34235607434150783   Training Accuracy: 87.11586378737542\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 400 of epoch 4 complete.\n",
            "Training Loss: 0.3475740819872169   Training Accuracy: 86.9466957605985\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 500 of epoch 4 complete.\n",
            "Training Loss: 0.35040240367491565   Training Accuracy: 86.78268463073853\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 600 of epoch 4 complete.\n",
            "Training Loss: 0.3524507796407341   Training Accuracy: 86.7824459234609\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 700 of epoch 4 complete.\n",
            "Training Loss: 0.3527776155190359   Training Accuracy: 86.80902282453637\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 800 of epoch 4 complete.\n",
            "Training Loss: 0.35429297619209754   Training Accuracy: 86.73923220973782\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 900 of epoch 4 complete.\n",
            "Training Loss: 0.35443264959621906   Training Accuracy: 86.74042730299666\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 1000 of epoch 4 complete.\n",
            "Training Loss: 0.3544960500789689   Training Accuracy: 86.71016483516483\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 1100 of epoch 4 complete.\n",
            "Training Loss: 0.35639496769529383   Training Accuracy: 86.61160308810173\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 1200 of epoch 4 complete.\n",
            "Training Loss: 0.35812055961625167   Training Accuracy: 86.57889258950874\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 1300 of epoch 4 complete.\n",
            "Training Loss: 0.3599554348127096   Training Accuracy: 86.51277863182167\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 1400 of epoch 4 complete.\n",
            "Training Loss: 0.36135809425049215   Training Accuracy: 86.48509992862242\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 1500 of epoch 4 complete.\n",
            "Training Loss: 0.36340294216947505   Training Accuracy: 86.3986508994004\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 1600 of epoch 4 complete.\n",
            "Training Loss: 0.3618811167855698   Training Accuracy: 86.44011555277952\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 1700 of epoch 4 complete.\n",
            "Training Loss: 0.36223402719666575   Training Accuracy: 86.42893885949441\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 1800 of epoch 4 complete.\n",
            "Training Loss: 0.36385140308219815   Training Accuracy: 86.36694891726819\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 1900 of epoch 4 complete.\n",
            "Training Loss: 0.36432479492837916   Training Accuracy: 86.36079694897423\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 2000 of epoch 4 complete.\n",
            "Training Loss: 0.3663457546574899   Training Accuracy: 86.25530984507746\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 2100 of epoch 4 complete.\n",
            "Training Loss: 0.3670018241944227   Training Accuracy: 86.2729057591623\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 2200 of epoch 4 complete.\n",
            "Training Loss: 0.36782025901269827   Training Accuracy: 86.254827351204\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 2300 of epoch 4 complete.\n",
            "Training Loss: 0.3689332020568982   Training Accuracy: 86.21387440243373\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 2400 of epoch 4 complete.\n",
            "Training Loss: 0.3704174948714267   Training Accuracy: 86.14119117034569\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 2500 of epoch 4 complete.\n",
            "Training Loss: 0.3706451654940641   Training Accuracy: 86.1280487804878\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 2600 of epoch 4 complete.\n",
            "Training Loss: 0.370874721936449   Training Accuracy: 86.10750672818146\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 2700 of epoch 4 complete.\n",
            "Training Loss: 0.3714168507389253   Training Accuracy: 86.07344502036283\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 2800 of epoch 4 complete.\n",
            "Training Loss: 0.37191244975525073   Training Accuracy: 86.05185647982863\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 2900 of epoch 4 complete.\n",
            "Training Loss: 0.371769867644808   Training Accuracy: 86.05760944501895\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 3000 of epoch 4 complete.\n",
            "Training Loss: 0.3715713561892072   Training Accuracy: 86.03798733755414\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 3100 of epoch 4 complete.\n",
            "Training Loss: 0.3720255209260969   Training Accuracy: 86.02063850370848\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 3200 of epoch 4 complete.\n",
            "Training Loss: 0.37202607519093694   Training Accuracy: 86.04635270228054\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 3300 of epoch 4 complete.\n",
            "Training Loss: 0.37224475731771306   Training Accuracy: 86.02790820963344\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 3400 of epoch 4 complete.\n",
            "Training Loss: 0.37278291165732313   Training Accuracy: 86.00503528374007\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 3500 of epoch 4 complete.\n",
            "Training Loss: 0.3736200980039809   Training Accuracy: 85.97989860039989\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 3600 of epoch 4 complete.\n",
            "Training Loss: 0.374146759288654   Training Accuracy: 85.95181893918355\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 3700 of epoch 4 complete.\n",
            "Training Loss: 0.3747501388731695   Training Accuracy: 85.92525668738179\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 3800 of epoch 4 complete.\n",
            "Training Loss: 0.37517334369296185   Training Accuracy: 85.90749144961852\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 3900 of epoch 4 complete.\n",
            "Training Loss: 0.37558893131517623   Training Accuracy: 85.89063701614971\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 4000 of epoch 4 complete.\n",
            "Training Loss: 0.3754039549028328   Training Accuracy: 85.90196200949762\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 4100 of epoch 4 complete.\n",
            "Training Loss: 0.37623260095006983   Training Accuracy: 85.85101194830528\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Batch 4200 of epoch 4 complete.\n",
            "Training Loss: 0.37606800856568423   Training Accuracy: 85.85455843846704\n",
            "Saving checkpoint at /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "\n",
            "*****\n",
            "\n",
            "The Total Accuracy for Epoch 4: 85.83938409895282\n",
            "Training Loss: 0.376187835754133\n",
            "Training Accuracy: 85.83938409895282\n",
            "\n",
            "Validation Loss: 0.644937407432331\n",
            "Validation Accuracy: 78.32660775399704\n",
            "\n",
            "Saving checkpoint at  /content/drive/My Drive/BERT project/Checkpoint/checkpoint.dat\n",
            "Saving model at  /content/drive/My Drive/BERT project/Model/4 \n",
            "\n",
            "================================================\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlKlVuour92k",
        "outputId": "bdafef97-1c3f-4774-a192-b75b9280a993",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Evaluation on test set\n",
        "for epoch in range(1, EPOCHS+1):\n",
        "  model = BertForSequenceClassification.from_pretrained(os.path.join(PROJECT_FOLDER, MODEL_FOLDER, str(epoch))).cuda()\n",
        "  print(f'Running validation on model trained on {epoch} epochs')\n",
        "\n",
        "  validate(model, test_loader)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running validation on model trained on 1 epochs\n",
            "Validation Loss: 0.5595950531298477\n",
            "Validation Accuracy: 79.40387709754042\n",
            "\n",
            "Running validation on model trained on 2 epochs\n",
            "Validation Loss: 0.5583814899391476\n",
            "Validation Accuracy: 79.92746405128598\n",
            "\n",
            "Running validation on model trained on 3 epochs\n",
            "Validation Loss: 0.5763244219915638\n",
            "Validation Accuracy: 79.16379332362781\n",
            "\n",
            "Running validation on model trained on 4 epochs\n",
            "Validation Loss: 0.6228458990793359\n",
            "Validation Accuracy: 78.89561464000204\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EisA-zFhz5Zf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}