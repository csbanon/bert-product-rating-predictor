{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Word_Clustering.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1R92h-2yELp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "344fa090-60ec-4cfd-eb79-0fc9a98caa44"
      },
      "source": [
        "# Import statements. \n",
        "import gensim, logging\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import ast\n",
        "from nltk import download, FreqDist, WordNetLemmatizer\n",
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn import datasets\n",
        "from sklearn.metrics import accuracy_score\n",
        " \n",
        "# Build sentences from review data.\n",
        "sentences = []\n",
        "word_list = []\n",
        "word_set = []\n",
        "data = pd.read_csv('https://raw.githubusercontent.com/csbanon/bert-product-rating-predictor/master/clustering_data/tokens_predicted_5.csv')\n",
        "print(data.axes)\n",
        "for comment in data['review']:\n",
        "  temp_sentence = ast.literal_eval(comment)\n",
        "  sentences.append(temp_sentence)\n",
        "  for word in temp_sentence:\n",
        "    word_list.append(word)\n",
        "\n",
        "frequency_dist = FreqDist(word_list)\n",
        "word_set = list(set([word for word in word_list if word !=\"\" and not word.isnumeric()]))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[RangeIndex(start=0, stop=29340, step=1), Index(['Unnamed: 0', 'review', 'prediction'], dtype='object')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMtY0mGUy7tg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7770a369-7487-4b23-8c20-631ae2b98149"
      },
      "source": [
        "# train word2vec on the two sentences\n",
        "model = gensim.models.Word2Vec(sentences, min_count=1)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-11-25 16:23:21,918 : INFO : collecting all words and their counts\n",
            "2020-11-25 16:23:21,919 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
            "2020-11-25 16:23:21,976 : INFO : PROGRESS: at sentence #10000, processed 236464 words, keeping 12522 word types\n",
            "2020-11-25 16:23:22,026 : INFO : PROGRESS: at sentence #20000, processed 470185 words, keeping 17241 word types\n",
            "2020-11-25 16:23:22,077 : INFO : collected 20702 word types from a corpus of 692673 raw words and 29340 sentences\n",
            "2020-11-25 16:23:22,078 : INFO : Loading a fresh vocabulary\n",
            "2020-11-25 16:23:22,119 : INFO : effective_min_count=1 retains 20702 unique words (100% of original 20702, drops 0)\n",
            "2020-11-25 16:23:22,120 : INFO : effective_min_count=1 leaves 692673 word corpus (100% of original 692673, drops 0)\n",
            "2020-11-25 16:23:22,194 : INFO : deleting the raw counts dictionary of 20702 items\n",
            "2020-11-25 16:23:22,196 : INFO : sample=0.001 downsamples 50 most-common words\n",
            "2020-11-25 16:23:22,196 : INFO : downsampling leaves estimated 631919 word corpus (91.2% of prior 692673)\n",
            "2020-11-25 16:23:22,256 : INFO : estimated required memory for 20702 words and 100 dimensions: 26912600 bytes\n",
            "2020-11-25 16:23:22,257 : INFO : resetting layer weights\n",
            "2020-11-25 16:23:27,028 : INFO : training model with 3 workers on 20702 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
            "2020-11-25 16:23:28,037 : INFO : EPOCH 1 - PROGRESS: at 96.53% examples, 609348 words/s, in_qsize 3, out_qsize 0\n",
            "2020-11-25 16:23:28,049 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-11-25 16:23:28,061 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-11-25 16:23:28,068 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-11-25 16:23:28,070 : INFO : EPOCH - 1 : training on 692673 raw words (632122 effective words) took 1.0s, 611370 effective words/s\n",
            "2020-11-25 16:23:29,088 : INFO : EPOCH 2 - PROGRESS: at 96.49% examples, 604440 words/s, in_qsize 3, out_qsize 0\n",
            "2020-11-25 16:23:29,090 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-11-25 16:23:29,100 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-11-25 16:23:29,103 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-11-25 16:23:29,104 : INFO : EPOCH - 2 : training on 692673 raw words (632023 effective words) took 1.0s, 616431 effective words/s\n",
            "2020-11-25 16:23:30,122 : INFO : EPOCH 3 - PROGRESS: at 97.98% examples, 614412 words/s, in_qsize 2, out_qsize 1\n",
            "2020-11-25 16:23:30,123 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-11-25 16:23:30,128 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-11-25 16:23:30,141 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-11-25 16:23:30,142 : INFO : EPOCH - 3 : training on 692673 raw words (631897 effective words) took 1.0s, 614919 effective words/s\n",
            "2020-11-25 16:23:31,148 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-11-25 16:23:31,158 : INFO : EPOCH 4 - PROGRESS: at 98.63% examples, 618484 words/s, in_qsize 1, out_qsize 1\n",
            "2020-11-25 16:23:31,159 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-11-25 16:23:31,167 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-11-25 16:23:31,168 : INFO : EPOCH - 4 : training on 692673 raw words (631786 effective words) took 1.0s, 621633 effective words/s\n",
            "2020-11-25 16:23:32,191 : INFO : EPOCH 5 - PROGRESS: at 96.49% examples, 601678 words/s, in_qsize 2, out_qsize 2\n",
            "2020-11-25 16:23:32,193 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2020-11-25 16:23:32,199 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2020-11-25 16:23:32,209 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2020-11-25 16:23:32,210 : INFO : EPOCH - 5 : training on 692673 raw words (631692 effective words) took 1.0s, 611971 effective words/s\n",
            "2020-11-25 16:23:32,212 : INFO : training on a 3463365 raw words (3159520 effective words) took 5.2s, 609571 effective words/s\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFbVB_5hD0mu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4318dcf2-2706-4878-9e71-394b9722df2a"
      },
      "source": [
        "# Testing\n",
        "top_words = frequency_dist.get('computer')\n",
        "print(top_words)\n",
        "print(model.wv['computer'])"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "621\n",
            "[-0.31534117  0.00725356 -0.11354424 -0.30353072 -0.05212222  1.014518\n",
            " -0.36917853 -0.68613374  0.4344511  -0.05051461 -0.5368282  -0.31623566\n",
            "  0.2487738   0.02004026  0.0284112   0.8526692   0.27090377  0.14540307\n",
            " -0.15304027  0.1427102  -0.30992174 -1.060559    1.0983423  -0.6307261\n",
            " -0.47346342 -0.2870233  -0.02979285  0.22083788  0.05377037  0.54229134\n",
            " -0.4828033  -0.03148756  0.5196573   0.02854848 -0.82863605 -0.41284472\n",
            "  0.14356743  1.0117517   0.06946371 -0.01912882  0.00173389 -0.5376283\n",
            " -0.2605944  -0.45136312 -0.92593753  0.14019379  0.10345034  0.30725998\n",
            "  0.46850967 -0.16337895 -0.10074654 -0.5862097  -0.26552865 -0.16341934\n",
            " -1.2119588   0.42923656  0.08763079 -0.86574125  0.21358761 -0.11940615\n",
            "  0.12111821 -0.22120863  0.7133103   1.0570287   0.5075445  -0.23019737\n",
            " -0.5138585   0.85307616  1.1395689   0.50121224 -0.64492726  0.73598444\n",
            "  0.5910498  -0.23985393 -0.35875228  0.12158713 -0.03731176  0.04585237\n",
            "  0.29201648 -0.24007073  0.7014852  -0.94085336  0.62842673  0.66939825\n",
            "  0.9189753   0.16555516  0.71240914 -0.49226904 -0.5370429   0.03912238\n",
            " -0.79307634 -0.9247483   0.21675734 -0.01325477  0.8050904   0.7035983\n",
            " -0.06376344  0.25679916  0.23120695 -0.415054  ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JI1D5tUeLPXN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea0c4934-d7db-4799-feb6-fa85c7ddfb72"
      },
      "source": [
        "kmeans = KMeans(n_clusters=5)\n",
        "kmeans.fit(model.wv.vectors)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
              "       n_clusters=5, n_init=10, n_jobs=None, precompute_distances='auto',\n",
              "       random_state=None, tol=0.0001, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjLbRPxqL3nL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b4a7a9e-a6d5-45a0-dd11-63d4df946dac"
      },
      "source": [
        "labels = kmeans.labels_\n",
        "centers = kmeans.cluster_centers_\n",
        "clusters = []\n",
        "clusters_count = []\n",
        "\n",
        "# Calculate Euclidian distance with vectorized words. \n",
        "def calc_distance(a, b):\n",
        "  total = 0\n",
        "  for i in range(0, a.size):\n",
        "    total += (a[i] - b[i]) ** 2\n",
        "  return np.sqrt(total)\n",
        "\n",
        "# Create a list of each value for each cluster. \n",
        "# This will make later operations much more efficient.\n",
        "for i in range(0, len(centers)):\n",
        "  cluster_list = []\n",
        "  cluster_list_count = []\n",
        "  for x in range(0, len(labels)):\n",
        "    if labels[x] == i:\n",
        "      cluster_list.append(word_set[x])\n",
        "      cluster_list_count.append(frequency_dist.get(word_set[x]))\n",
        "  clusters.append(cluster_list)\n",
        "  clusters_count.append(np.array(cluster_list_count))\n",
        "\n",
        "# Print words of each cluster.\n",
        "for i in range(0, len(clusters)):\n",
        "  print(\"\\nWords in cluster \", i+1)\n",
        "  top_5_index = clusters_count[i].argsort()[-5:][::-1]\n",
        "  top_5 = []\n",
        "  top_5_count = []\n",
        "  for index in top_5_index:\n",
        "    top_5.append(clusters[i][index])\n",
        "    top_5_count.append(frequency_dist.get(clusters[i][index]))\n",
        "  print(top_5)\n",
        "  print(top_5_count)\n",
        "\n",
        "# Find the center word for each cluster. \n",
        "center_words = []\n",
        "center_word_distances = []\n",
        "\n",
        "for i in range(0, 5):\n",
        "  distances = []\n",
        "  for x in range(0, len(word_set)):\n",
        "    distances.append(calc_distance(centers[i], model.wv[word_set[x]]))\n",
        "  mins = min(distances)\n",
        "  mins_index = distances.index(mins)\n",
        "  center_word_distances.append(mins)\n",
        "  center_words.append(word_set[mins_index])\n",
        "\n",
        "print(center_words)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Words in cluster  1\n",
            "['not', 'work', 'sound', 'one', 'good']\n",
            "[9104, 7559, 6387, 6060, 5891]\n",
            "\n",
            "Words in cluster  2\n",
            "['alexa', 'put', 'show', 'started', 'cannot']\n",
            "[1888, 1035, 990, 406, 392]\n",
            "\n",
            "Words in cluster  3\n",
            "['great', 'no', 'phone', 'device', 'even']\n",
            "[9451, 4243, 3885, 2558, 2283]\n",
            "\n",
            "Words in cluster  4\n",
            "['camera', 'paper', 'different', 'reason', 'whole']\n",
            "[3165, 1098, 917, 494, 239]\n",
            "\n",
            "Words in cluster  5\n",
            "['would', 'local', 'generation', 'status', 'motherboard']\n",
            "[4105, 285, 129, 88, 34]\n",
            "['aos', 'honestly', 'challenge', 'basically', 'excelente']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2F9DR0kxU_UZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7d82e68-f4e0-4fed-93cb-63e3c5b8a40c"
      },
      "source": [
        "print(center_words)\n",
        "print(center_word_distances)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['aos', 'honestly', 'challenge', 'basically', 'excelente']\n",
            "[0.0349795329042444, 1.760378641942225, 0.462598645284901, 1.7748286672736797, 0.7348057779545784]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}